{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d2ef6-dea8-4d0f-bb80-99fb65760147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use kernel [conda env:ml]\n",
    "import os\n",
    "import csv\n",
    "import _csv\n",
    "import psutil\n",
    "import multiprocessing as mp\n",
    "from typing import TextIO, Union, List\n",
    "\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from collections import Counter\n",
    "import time\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "#from aggregator_multi import create_graph\n",
    "# from .projection_data import projection_data_class\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import statsmodels.api as sm #for linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03dabac-a3fe-468a-a6b1-396494250623",
   "metadata": {},
   "source": [
    "## Step 1: Load road network from OSM and preprocess\n",
    "Preprocessing is done by removing edges in the network that we don't need, like sidewalks. This is done with the thin_edges fuction written by Yvonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d822d6-5fae-46f2-8c1a-75813dea95a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def thin_edges(edges, keep_types=None):\n",
    "    # removes edges from specific types, useful when we only want to use primary roads and no residential or tertiary\n",
    "    # roads.\n",
    "    # see https://wiki.openstreetmap.org/wiki/Map_features#Highway for a list of values.\n",
    "    # some EDA has lead us to the default values. In our application it more important not to remove too many types,\n",
    "    # as long as the largest batches of unnecessary edges are removed\n",
    "\n",
    "    # all from the wiki that have a \"way\" element icon\n",
    "    all_types = [\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\", \"residential\",\n",
    "                 \"motorway_link\", \"trunk_link\", \"primary_link\", \"secondary_link\", \"tertiary_link\",\n",
    "                 \"living_street\", \"service\", \"pedestrian\", \"track\", \"bus_guideway\", \"escape\", \"raceway\", \"road\",\n",
    "                 \"busway\", \"footway\", \"bridleway\", \"steps\", \"corridor\", \"path\", \"cycleway\", \"elevator\",\n",
    "                 \"emergency_bay\", \"platform\", \"User Defined\"]\n",
    "\n",
    "    if keep_types is None:\n",
    "        # default value\n",
    "        keep_types = [\"motorway\", \"trunk\", \"primary\",\"motorway_link\", \"trunk_link\", \"primary_link\", \"escape\"]\n",
    "\n",
    "    remove_types = [x for x in all_types if x not in keep_types]\n",
    "    print(\"Removed types: \" + str(remove_types))\n",
    "\n",
    "    len_1 = len(list(edges[\"highway\"]))\n",
    "\n",
    "    for rt in remove_types:\n",
    "        edges.drop(edges.index[edges[\"highway\"] == rt], inplace=True)\n",
    "\n",
    "    print(\"Edges have been thinned. Only \" + str(len(list(edges[\"highway\"])))\n",
    "          + \" edges remain from original \" + str(len_1))\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1cf733-64d6-496f-bb8d-e9ef053f54dc",
   "metadata": {},
   "source": [
    "##### Loading data, setting crs and thinning edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460385b-c155-4d9f-9e38-8c6a50d3083d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = ox.geocode_to_gdf(\"Netherlands\") # previously this function was gdf_from_places\n",
    "\n",
    "# get a graph of the union of their boundaries, then extract nodes as geodataframe\n",
    "G = ox.graph_from_polygon(gdf.unary_union, network_type='drive')\n",
    "\n",
    "crs_rds = pyproj.crs.CRS(\"EPSG:28992\")\n",
    "crs_to = crs_rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156cade-6a7f-4b85-8394-6b4c09dc48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add edge bearings for later\n",
    "G = ox.add_edge_bearings(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704ff57-e5b2-4382-95d3-fdcdbbeb3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert graph to rds\n",
    "Ugraph = ox.project_graph(G, to_crs=crs_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a50cef-4024-47bc-bdb4-7c1d34ee0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thin edges and put nodes and thinned edges together in a graph object \n",
    "nodes, edges = ox.graph_to_gdfs(Ugraph)\n",
    "edges = thin_edges(edges)\n",
    "Ngraph = ox.graph_from_gdfs(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3aae3-2c00-4f49-a8c6-13ab19fdd6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file \n",
    "#ox.io.save_graph_geopackage(Ngraph, filepath=\"Ngraph_undirected.gpkg\", encoding='utf-8', directed=False)\n",
    "#ox.io.save_graph_geopackage(Ngraph, filepath=\"Ngraph_directed.gpkg\", encoding='utf-8', directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd2c0f-b04a-4a2f-b633-d931b392b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ngraph = gpd.read_file(\"Ngraph_directed.gpkg\") #didn't work once I tried getting nearest edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1d0c6-079c-442d-a54f-8a622fc16b17",
   "metadata": {},
   "source": [
    "## Step 2: Load Sensor data and assign each sensor to nearest edge\n",
    "The latter is done with the nearest_edges function from the osmnx package. This also returns the distance to the nearest edge (unit = 100km) if you don't change anything in the sensor's location. \n",
    "<br> This is because the Coordinate Reference System (CRS) is 4326, which is the typical longitude/latitude, and not that exact when you project onto a 2D map and want distances in meters. \n",
    "<br> To get more exact distances in meters, we change the CRS to EPSG:28992, which is optimal for the Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb19af5-73e3-47cf-93bc-99d1f34390b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmap_classified_df = pd.read_csv(\"nlmap_classified_df.csv\")\n",
    "\n",
    "nlmap_classified_gdf = gpd.GeoDataFrame(\n",
    "    nlmap_classified_df, geometry=gpd.points_from_xy(nlmap_classified_df.longitude, nlmap_classified_df.latitude))\n",
    "\n",
    "nlmap_classified_gdf.crs = \"EPSG:4326\"\n",
    "nlmap_classified_gdf = nlmap_classified_gdf.to_crs(\"EPSG:28992\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ff7b8-e029-43d3-adf7-fefd69ef881a",
   "metadata": {},
   "source": [
    "The nearest_edges function returns a warning message that does not seem to be a problem, but is not fully understood yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9632c4e-60eb-498e-97fc-ba19ceab0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_edges = ox.distance.nearest_edges(Ngraph, nlmap_classified_gdf.geometry.x, nlmap_classified_gdf.geometry.y, interpolate=None, return_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26323e85-ca05-46d6-837c-219a7d47c2af",
   "metadata": {},
   "source": [
    "## Step 3: Put results into a comprehensible dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd85594-24b8-4ed8-9051-b7ac5de240b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_edges_df = pd.DataFrame(all_used_edges)\n",
    "all_used_edges_df = all_used_edges_df.transpose() #to have two columns in total instead of 1 column per sensor\n",
    "all_used_edges_df.columns = [\"edges\", \"distance\"] \n",
    "all_used_edges_df[\"location_id\"] = nlmap_classified_df[\"location_id\"].tolist() #add location_id to each edge-distance\n",
    "all_used_edges_df[\"PV_NAAM\"] = nlmap_classified_df[\"PV_NAAM\"].tolist()\n",
    "all_used_edges_df[['node_from', 'node_to', 'zero']] = pd.DataFrame(all_used_edges_df['edges'].tolist(), index=all_used_edges_df.index)\n",
    "all_used_edges_df.drop('zero', inplace = True, axis = 1)\n",
    "all_used_edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33abb4-5015-4672-acd6-c1633cbbf2a0",
   "metadata": {},
   "source": [
    "#### (Save as CSV), uncomment as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c126cd0-1666-4c93-8fee-fd90e9232cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_used_edges_df.to_csv('edges_and_sensors.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac89155-239f-4267-b908-63a7e3025cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_used_edges_df = pd.read_csv(\"edges_and_sensors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5bf4b-ae2e-4d58-965e-330df5afacd8",
   "metadata": {},
   "source": [
    "## Step 4: Assign average sum of workdays to edge-sensor\n",
    "Only including Tuesdays, Wednesdays and Thursdays, only including month of May, using sample of all observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc62ab5-a416-40e3-9f2c-9ecd2dc976da",
   "metadata": {},
   "source": [
    "##### Load intensities and remove weekdays that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209a896-388c-466f-a2d7-967886e1c5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entire_rushhour = pd.read_csv(\"entire_rushhour_shortssummed_datetime.csv\")\n",
    "entire_rushhour = entire_rushhour.loc[entire_rushhour[\"month\"] == 5]\n",
    "entire_rushhour[\"time\"] = pd.to_datetime(entire_rushhour['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "entire_rushhour[\"dayofweek\"] = entire_rushhour.time.dt.dayofweek\n",
    "ent_tu_we_th = entire_rushhour[entire_rushhour[\"dayofweek\"].isin([1,2,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a961b36-8bb4-45ec-89d9-b5c0d5df1d73",
   "metadata": {},
   "source": [
    "First sum over each day, then average over all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4dc4d-de76-4e84-8b33-cb4a054007f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_tu_we_th_grouped = ent_tu_we_th[[\"location_id\", \"date\", \"value\"]]\n",
    "\n",
    "#first sum up for each day\n",
    "ent_tu_we_th_grouped = ent_tu_we_th_grouped.groupby([\"location_id\", \"date\"], as_index = False).sum()\n",
    "\n",
    "#then get average sum of working days\n",
    "ent_tu_we_th_grouped = ent_tu_we_th_grouped.groupby([\"location_id\"], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341e610-f0f1-49f5-90b3-ed13b3543823",
   "metadata": {},
   "source": [
    "Merge with all_used_edges_df and rename  value to \"obs\" for observed counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be7338-a73e-4354-b036-5d0a258eef9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges_intensities = all_used_edges_df.merge(ent_tu_we_th_grouped, on = \"location_id\", how = \"outer\")\n",
    "edges_intensities = edges_intensities.rename(columns = {\"value\": \"obs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f5b26-c736-4cd0-8041-75ea40f577b8",
   "metadata": {},
   "source": [
    "#### Add longitude and latitude from meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c2352-e179-4acf-95f4-280174313dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"meta211121.csv\")\n",
    "meta = meta.rename(columns = {\"dgl_loc\": \"location_id\"})\n",
    "meta = meta[[\"location_id\", \"coordinates\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd2ab9-5ce8-4dfb-8ce5-ca1da997c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_intensities = edges_intensities.merge(meta, on = \"location_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653c084-e9fb-4d2d-915b-fa7787929a0f",
   "metadata": {},
   "source": [
    "#### (Save as CSV), uncomment as desired\n",
    "#### If you do not have access to CBS, you can load edges_intensities from the repository at this step to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd0138-e78b-4242-9206-f86681c34fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges_intensities.to_csv('edges_intensities.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff5608-c8cc-4b5f-ba4d-6eaf0b8213f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges_intensities = pd.read_csv('edges_intensities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823a79c-2058-4a2f-9d35-7705467f1ca5",
   "metadata": {},
   "source": [
    "Remove rows with NA's (necessary for visualisation) and rows with 0-counts, which are malfunctioning sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b62af9-0aeb-435f-a2ff-a471422a7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_intensities = edges_intensities.dropna(subset=['obs', 'edges'])\n",
    "edges_intensities = edges_intensities.loc[edges_intensities.obs > 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8873a42-89a4-46f7-bded-b6c189330554",
   "metadata": {},
   "source": [
    "## Step 5: Correct false directions\n",
    "The longitude and latitude in the metadata do not refer exactly to the point of measurement (i.e. the lane on which cars are counted), but to a device placed next to the road. This device might collect the measurements of multiple sensors that are placed on lanes that go in different directions (which are considered seperate roads). We use the \"meetricht\" variable from the meta-data that gives the bearing of the road at the point of measurement and compare it to the bearing of the OSM edge. If the meetricht and the bearing are in opposite directions, we swap the node_from and node_to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5f503-d1da-43fa-9997-4e35633d84c2",
   "metadata": {},
   "source": [
    "First extract direction from metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd0a87-a095-408a-86db-f256dd7693fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"meta211121.csv\")\n",
    "meta_dir = meta[[\"meetricht\", \"dgl_loc\"]]\n",
    "meta_dir = meta_dir.rename(columns = {\"dgl_loc\": \"location_id\"})\n",
    "meta_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e72294-b774-4e2b-9bb4-40ceecbb04a4",
   "metadata": {},
   "source": [
    "The metadata contains the meetricht variable, which is missing for around half the sensors in 2019. NDW sent me a shapefile containing another meetricht variable. The file can be requested at the NDW servicedesk (https://www.ndw.nu/contact). This one only contains ~2000 of the sensors that we look at for 2019. Most of the times, when the meetricht variable is missing in the metadata, it is observed in the shapefile. For cases where both are observed, they are almost the same in the vast majority (mean difference of -1). I therefore decided to merge those two to be able to keep more sensors in the dataset. \n",
    "<br> I refer to the meta data meetricht as \"oldmeetricht\" and to the shapefile meetricht as \"meetricht\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ecb1f7-e1ac-4f8d-86e0-b05604623323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwdir = gpd.read_file(\"Data/NDW/Shapefile/Telpunten/Telpunten_WGS84.shp\")\n",
    "ndwdir = ndwdir[[\"dgl_loc\", \"meetricht\"]].rename(columns = {\"dgl_loc\": \"location_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858c861-219c-45db-864e-66622da638ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities_ndwdir = edges_intensities.merge(ndwdir, on='location_id', how = \"left\")\n",
    "intensities_ndwdir.meetricht.isna().sum() #check how many are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bf328-1cb3-4bc7-821f-8152037df6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities_ndwdir2 = intensities_ndwdir.loc[intensities_ndwdir.edges.notna()] #remove sensors that were not used in our 2019 dataset\n",
    "\n",
    "meta_dir2 = meta_dir.rename(columns = {\"meetricht\": \"oldmeetricht\"}) #to be able to distinguish shapefile meetricht from metadata meetricht\n",
    "\n",
    "allmeet = meta_dir2.merge(intensities_ndwdir2, on = \"location_id\", how = \"outer\")\n",
    "\n",
    "allmeet = allmeet.loc[allmeet.edges.notna()]\n",
    "allmeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e489d-3506-409f-bda8-4dd69f389e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmeet[\"meetdiff\"] = allmeet.oldmeetricht - allmeet.meetricht\n",
    "allmeet.meetdiff.hist(bins = 100)\n",
    "plt.title('Difference between oldmeetricht and meetricht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5654b-aa78-4d58-8b04-4fe454a4f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new with correct crs\n",
    "allmeet.meetdiff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8681f-e45a-4e27-acc4-749e2d8f2ee5",
   "metadata": {},
   "source": [
    "In most cases, the difference between the meta meetricht and the shapefile meetricht is 0. I remove cases where the difference is larger than 5 and assume that a difference of less than 5 can be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21992939-3497-4413-91ff-02d5126cbaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allmeet = allmeet.loc[ ((allmeet.meetdiff.isna()) | (abs(allmeet.meetdiff) < 5)) & (allmeet.meetricht.notna() | allmeet.oldmeetricht.notna()) ] #cases were at least one of the two was observed and the differnce was not large\n",
    "allmeet #4771 rows left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892360e-a5ec-4fad-b2bf-5159038cf06a",
   "metadata": {},
   "source": [
    "Finally, we have to create a new column for the direction. I decided to favor the oldmeetricht for cases where both are observed. In other cases, only the observed one is kept. This assumes that in missing meetricht values in the metadata, the meetricht in the shapefile is the correct one and vice versa. We name this new column meetricht and name the other two columns accordingly to their origin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708e449-8232-4faa-ba8e-cc3b0c3df6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmeet[\"finalmeetricht\"] = np.where(allmeet.oldmeetricht.isna(), allmeet.meetricht, allmeet.oldmeetricht)\n",
    "allmeet = allmeet.rename(columns = {\"oldmeetricht\": \"meta_meetricht\", \"meetricht\": \"ndw_meetricht\", \"finalmeetricht\": \"meetricht\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750f49a-a86c-4418-89ea-6b569c086a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old chunk, this is how I extracted the direction before using the shapefile\n",
    "#intensities_dir = edges_intensities.merge(meta_dir, on='location_id', how = \"left\")\n",
    "\n",
    "#intensities_dir = intensities_dir.dropna() #not all sensors have a meetricht-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a02ee9-34da-4305-ba2a-a809dbe2e0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intensities_dir #3516 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e587d-5064-4bde-aa89-23c2864b51ef",
   "metadata": {},
   "source": [
    "### Get the bearing of each edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12257e3e-8b06-421a-a81c-2aa066f54189",
   "metadata": {},
   "source": [
    "### Visualization of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81fa5b-89b8-449a-b8d5-a4c4881b57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_edge(df, edges, features = [\"added_feature\"], node_from = \"node_from\", node_to = \"node_to\", indexerror = np.nan):\n",
    "\n",
    "    # Code is a simplified and generalized version of Yvonne Gootzen's visualize_intensities function\n",
    "    edge_idx_0 = [idx[0] for idx, _ in edges.iterrows()]\n",
    "    edge_idx_1 = [idx[1] for idx, _ in edges.iterrows()]\n",
    "    \n",
    "    n_features = len(features)\n",
    "    features_list = [[] for _ in range(n_features)]\n",
    "    for nf, nt in zip(edge_idx_0, edge_idx_1):\n",
    "        for n in range(n_features): #for each feature\n",
    "    \n",
    "            try:\n",
    "                # search in intensities for a have a matching edge\n",
    "                feat = df.loc[(df[node_from] == nf) & (df[node_to] == nt), features[n]].iloc[0]\n",
    "\n",
    "                features_list[n].append(feat)\n",
    "\n",
    "            except IndexError:\n",
    "                features_list[n].append(indexerror)\n",
    "\n",
    "\n",
    "    for m in range(n_features):\n",
    "        edges[features[m]] = features_list[m]\n",
    "    \n",
    "    return edges\n",
    "\n",
    "edges2 = add_features_to_edge(allmeet, edges, features = [\"meetricht\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986210a-4b33-4ac9-8731-597417c9fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_dirbear = edges2.dropna(subset = [\"meetricht\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b4acd-d268-4b6a-bdc4-96111fc855a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new, without emergency bay\n",
    "plt.scatter(edges_dirbear.meetricht, edges_dirbear.bearing, s = 1)\n",
    "plt.show()\n",
    "#add a straight line in this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a8e22-e064-4768-ae4b-5a39f12d5c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges_dirbear[\"diff\"] = edges_dirbear[\"meetricht\"] - edges_dirbear[\"bearing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f291265-1faa-4f78-a460-44e148d33c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new, without emergency bay\n",
    "edges_dirbear[\"diff\"].hist(bins = 100)\n",
    "plt.title('Difference between sensor direction and edge bearing ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c4d02-9902-4d2d-baba-24ddaefa9c87",
   "metadata": {},
   "source": [
    "Below is code that can do a similar thing as the add_features_to_edges function, but the other way around, where it adds features from edges to the dataframe. This is faster, and can be useful if we do not need the entire edge dataset. I am keeping this here for the next person at CBS working with sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d79e5-3b2e-4981-a6f5-047319d96f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allmeet was intensities_dir\n",
    "\n",
    "#extract u, v and bearing\n",
    "edge_bearing_idx_0 = [idx[0] for idx, _ in edges.iterrows()]\n",
    "edge_bearing_idx_1 = [idx[1] for idx, _ in edges.iterrows()]\n",
    "edge_bearing_bearing = edges.bearing.tolist()\n",
    "\n",
    "#create dictionary \n",
    "edge_bearing_idx_01 = list(zip(edge_bearing_idx_0, edge_bearing_idx_1))\n",
    "bearing_dict = dict(zip(edge_bearing_idx_01, edge_bearing_bearing))\n",
    "\n",
    "#create node_from_to variable in dataframe\n",
    "allmeet[\"node_from_to\"] = list(zip(allmeet[\"node_from\"], allmeet[\"node_to\"]))\n",
    "\n",
    "#create bearing variable using dictionary\n",
    "allmeet[\"bearing\"] = allmeet[\"node_from_to\"].map(bearing_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f77e7b-6570-4fb7-a40e-d8e16959c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allmeet was intensities_dir\n",
    "allmeet[\"direction_differences\"] = allmeet.meetricht - allmeet.bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591bf5e-71ec-49ca-b519-b8a9c94f7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allmeet was intensities_dir\n",
    "plt.scatter(allmeet.meetricht, allmeet.bearing, s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e98a6-d474-4c13-95e0-7ca28fe6a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "plt.style.use(\"bmh\")\n",
    "# Plots #\n",
    "    # Plot scatter\n",
    "plt.scatter(allmeet.bearing,allmeet.meetricht, s = 1)\n",
    "\n",
    "#add diagonal line\n",
    "ax.axline((1, 1), slope=1, color = \"grey\", ls = \"-\", linewidth = 1, alpha = 0.9)\n",
    "\n",
    "# X #\n",
    "ax.set_xlabel(\"OSM edge\")\n",
    "\n",
    "# Y #\n",
    "#ax.set_yticks([])\n",
    "ax.set_ylabel(\"Sensor metadata\")\n",
    "\n",
    "# Overall #\n",
    "#ax.set_title(\"Sensor bearing against road segment bearing\")\n",
    "# Remove ticks and spines\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.rcParams['font.family'] = ['serif']\n",
    "#fig.savefig(\"figures/edges_bearing.pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi=10, format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7aeaf1-c496-4d19-bb7c-5e420d80eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmeet.distance.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f917292-c180-4228-ab46-f0825591e5a7",
   "metadata": {},
   "source": [
    "Flip node_from and node_to where the difference is between 90-270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54635fc8-0720-4d77-b2f4-2f6577a86ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in new object called \"obs\" for observed counts\n",
    "traffic = allmeet\n",
    "traffic[\"abs_direction_differences\"] = abs(traffic[\"direction_differences\"])\n",
    "traffic[\"node_from_flip\"] = np.where((traffic[\"abs_direction_differences\"] > 90) & (traffic[\"abs_direction_differences\"] < 270), traffic[\"node_to\"], traffic[\"node_from\"])\n",
    "traffic[\"node_to_flip\"] = np.where((traffic[\"abs_direction_differences\"] > 90) & (traffic[\"abs_direction_differences\"] < 270), traffic[\"node_from\"], traffic[\"node_to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d2caf-3e10-47fd-bc25-80672f56e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic.rename(columns = {\"node_from\": \"node_from_old\", \"node_to\": \"node_to_old\"})\n",
    "traffic = traffic.rename(columns = {\"node_from_flip\": \"node_from\", \"node_to_flip\": \"node_to\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6c839-b55d-4d61-a125-32777ae1b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "#obs.to_csv('intensities_dir_flipped.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f90db-7555-4247-803f-782020a8381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs = pd.read_csv(\"intensities_dir_flipped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15055082-d630-4fcf-9c04-282276d68091",
   "metadata": {},
   "source": [
    "Plot histogram of observed counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b0100-7f0f-4c93-825c-4745aaaf3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "plt.style.use(\"bmh\")\n",
    "# Plots #\n",
    "    # Plot histogram\n",
    "traffic[\"obs\"].plot(kind = \"hist\", density = False, alpha = 0.8, bins = 70) # change density to true, because KDE uses density\n",
    "\n",
    "# X #\n",
    "ax.set_xlabel(\"Counts\")\n",
    "\n",
    "# Y #\n",
    "#ax.set_yticks([])\n",
    "    # Relabel the axis as \"Frequency\"\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Overall #\n",
    "ax.set_title(\"Observed traffic counts\")\n",
    "# Remove ticks and spines\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.rcParams['font.family'] = ['serif']\n",
    "#fig.savefig(\"figures/obs_hist.pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi=10, format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb657b50-49e5-499e-93a8-f8c372348f46",
   "metadata": {},
   "source": [
    "## Step 6: Visualize intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93891060-8e41-46d8-9436-94554ec709d9",
   "metadata": {},
   "source": [
    "The value-variable has a wide spread. For plotting with a colorscale, we need it to be normally distributed. We achive this by applying a cube root transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33add874-bb69-4d60-b7f9-7cb582494e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic[\"obscb\"] = traffic.obs**(1/3)\n",
    "traffic[\"obscb\"].hist(bins = 100)\n",
    "plt.title(\"Distribution of observed traffic count after $\\sqrt[3]{.}$-transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085da318-da11-4e95-b02c-3a7b2c97386d",
   "metadata": {},
   "source": [
    "#### Add obs and obscb to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcca25-8ef7-4b71-a3fe-e92a8c4e6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges2 = add_features_to_edge(traffic, edges2, features = [\"obs\", \"obscb\"], node_from = \"node_from\", node_to = \"node_to\", indexerror = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6b465-e95f-4400-9fb2-7f4e56c4bdd1",
   "metadata": {},
   "source": [
    "#### Next, create custom colormap to grey out edges that do not have sensors\n",
    "The first value on the scale (0) will be grey, rest will range from yellow to blue\n",
    "(code found on stackoverflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927846f-56a8-4008-8cac-d66ca1bc260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_examples(colormaps, lo = 1, hi = 100):\n",
    "    \"\"\"\n",
    "    Helper function to plot data with associated colormap.\n",
    "    \"\"\"\n",
    "    np.random.seed(19680801)\n",
    "    data = np.random.randint(low = lo, high = hi, size = (30,30))\n",
    "    n = len(colormaps)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(n * 2 + 2, 3),\n",
    "                            constrained_layout=True, squeeze=False)\n",
    "    for [ax, cmap] in zip(axs.flat, colormaps):\n",
    "        psm = ax.pcolormesh(data, cmap=cmap, rasterized=True, vmin=lo, vmax=hi)\n",
    "        fig.colorbar(psm, ax=ax)\n",
    "    plt.show()\n",
    "#modify colormap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fe2a2-9596-494c-bcd3-59ebaf361db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_plot.exp_car.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18002597-7935-4d08-b607-fecc6f52a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create colorscales\n",
    "# Diverging color scale to see both below and above 1 values, set lowest value to grey colour\n",
    "# colormap for c\n",
    "seismic = cm.get_cmap('seismic', 101)\n",
    "seismic_colors = seismic(np.linspace(0.175, 1, 101))\n",
    "darkgrey = np.array([0.5, 0.5, 0.5, 0.15]) #the fourth value sets the transparency of the color. This is necessary, because the grey roads would otherwise cover up the colored roads\n",
    "seismic_colors[:1 :] = darkgrey\n",
    "seismiccmp = ListedColormap(seismic_colors)\n",
    "\n",
    "#colormap for c*\n",
    "#get min and max of cs_plot to cut off top and bottom of scale, multiply by 0.01 to get value between 0 and 1\n",
    "cs_min = edges_calibrated[\"cs_plot\"].min() * 0.01\n",
    "cs_max = edges_calibrated[\"cs_plot\"].max() * 0.01\n",
    "\n",
    "seismic_colors2 = seismic(np.linspace(cs_min+ 0.175, cs_max, 101))\n",
    "seismic_colors2[:1 :] = darkgrey\n",
    "\n",
    "seismiccmp2 = ListedColormap(seismic_colors2)\n",
    "\n",
    "plot_examples([seismiccmp, seismiccmp2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47689f-21d6-4cd0-9232-6ef88ead34d0",
   "metadata": {},
   "source": [
    "ec = ox.plot.get_edge_colors_by_attr(graph, attr=\"intensity\", cmap= newcmp)\n",
    "\n",
    "fig, ax = ox.plot_graph(graph, node_color=\"w\", node_edgecolor=\"k\", node_size=0, edge_color=ec, edge_linewidth=2) #weights does not work for linewidth\n",
    "\n",
    "plt.show()Assign colors to edges based on intensity and plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9f950-3566-4a49-93f6-83b596baaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create colorbar that has the first value 0 mapped to the color grey (edges with no sensors have \"0\" for the observed count - these will be grey in the plot)\n",
    "hot = cm.get_cmap('hot', int(traffic[\"obscb\"].max()))\n",
    "newcolors = hot(np.linspace(0.1, 1, int(traffic[\"obscb\"].max())))\n",
    "darkgrey = np.array([0.5, 0.5, 0.5, 0.15]) #the fourth value sets the transparency of the color. This is necessary, because the grey roads would otherwise cover up the colored roads\n",
    "newcolors[:1 :] = darkgrey\n",
    "\n",
    "newcmp1 = ListedColormap(newcolors)\n",
    "\n",
    "plot_examples([hot, newcmp1], lo = traffic[\"obscb\"].min(), hi = traffic[\"obscb\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b658ec-2e4d-49eb-ab8b-3edbab152cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(traffic.obs, traffic.obscb)\n",
    "plt.title(\"Transformed vs. untransformed obs (shows what each color represents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a5bfd-fbdc-4045-b2e3-8c84d575fd0f",
   "metadata": {},
   "source": [
    "Now we have to take care of the legend of the plot. This is important, because we want the plot to be informative and also comparable to the same plot for expected counts. Both observed and expected counts are cube root transformed. To have a more gradual change in colors and to get rid of the grey color at the bottom, we create another colormap specifically for the colorbar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dc2fc-9a61-4a33-b02e-1a95c0251f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colorbar\n",
    "hot_cb = cm.get_cmap('hot', 512)\n",
    "newcolors_cb = hot_cb(np.linspace(0, 1, 512))\n",
    "\n",
    "newcmp_cb = ListedColormap(newcolors_cb)\n",
    "plot_examples([newcmp_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91141c-cf8b-41b3-8a02-e8657a7a353e",
   "metadata": {},
   "source": [
    "The transformed counts in obscb range from 0-25. For the plot, we want to have a legend with tick labels with the backtransformed observed counts at 5, 10, 15, 20 and 25. For example, the observed count at the first tick label is 5^3 = 125 cars. To keep the tick labels short, I use scientific notation, i.e. 125 cars written as $1.3 \\times 10^2$ cars.\n",
    "<br> The position of these tick labels on the legend needs to be given on a scale of 0-1. To get the first position, we can compute 5/obs.obscb.max(). To get the second position, 5/obs.obscb.max() * 2, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926a4f5-47ae-492d-a573-db9e5675b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tick label positions\n",
    "for i in range(1,6): print((5 / traffic[\"obscb\"].max()) * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79c819-8399-4a0d-8f34-802ae0b48840",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ox.graph_from_gdfs(nodes, edges2)\n",
    "ec = ox.plot.get_edge_colors_by_attr(graph, attr=\"obscb\", cmap= newcmp1)\n",
    "\n",
    "fig, ax = ox.plot_graph(graph, node_color=\"w\", node_edgecolor=\"k\", node_size=0, edge_color=ec, edge_linewidth=2, show = False) \n",
    "\n",
    "# add colorbar\n",
    "sm = mpl.cm.ScalarMappable(cmap = newcmp_cb)\n",
    "sm.set_array([])\n",
    "cb = fig.colorbar(cm.ScalarMappable(cmap = newcmp_cb), ax = ax, location = 'right', shrink = 0.8, ticks = [0.198, 0.396, 0.594,0.792,0.998])\n",
    "cb.ax.set_yticklabels([r'$1.3 \\times 10^2$', r'$1 \\times 10^3$', r'$3.4 \\times 10^3$', r'$8 \\times 10^3$',r'$1.56 \\times 10^4$'])\n",
    "cb.ax.set_ylabel('observed cars', rotation = 90)\n",
    "\n",
    "\n",
    "#fig.savefig(\"playgorund/obs_intensities.pdf\", format = \"pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi = 1000) #bbox_inches and pad_inches ensure that there is no white frame around the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55070725-be08-4343-b5d6-b0baf3c986ec",
   "metadata": {},
   "source": [
    "## Step 7: Visualize expected counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fdc0e-c5c4-450a-a3b0-8b52fb0a4cab",
   "metadata": {},
   "source": [
    "If you don't have access to CBS data, you can <b> generate expected counts for each edge on the OSM network </b>. The expected count data resembles a gamma distribution with shape parameter = 1.1 and scale parameter = 3000. Uncomment the lines in the below chunk to create this synthetic data set of expected counts, and comment the line in the following chunk that tries to read the expected counts from CBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a093f-5955-493b-98a8-f153c019a1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp_synth = edges2\n",
    "#exp_synth = pd.DataFrame(exp_synth.reset_index())\n",
    "#exp_synth[\"node_from\"] = exp_synth[\"u\"]\n",
    "#exp_synth[\"node_to\"] = exp_synth[\"v\"]\n",
    "#exp_synth = exp_synth[[\"node_from\", \"node_to\"]]\n",
    "#exp_synth[\"exp_car\"] = np.random.gamma(shape = 1.1, scale = 3000, size =  len(exp_synth))\n",
    "#exp_synth[\"exp_car\"].hist(bins = 100)\n",
    "#exp = exp_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaef00-d96c-4f9c-a914-435a3e158971",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv('/data2/dacimob/wk_2019_CAR_15_v2.EXPECTED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b420aa3-cbfc-40ce-88e1-522bf68608ad",
   "metadata": {},
   "source": [
    "There are 12 entries in the data set that do not have a node_from or node_to (they also have extremely high expected counts). I remove these entries, because they are likely errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ecac0-d025-4f40-8cbc-7c7b8d2ad932",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = exp.loc[~exp.node_from.isna()]\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa71ec2-c4af-4882-b310-11784ab42476",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[\"node_from_to_new\"] = list(zip(exp.node_from, exp.node_to))\n",
    "len(exp.node_from_to_new.unique()) - len(exp) #no duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81423afa-a827-4e88-a624-63315c47a87e",
   "metadata": {},
   "source": [
    "In the thesis, I showed a histogram of expected counts, but only for the road segments where we also have observed counts, so that those two histograms can be more comparable. For this, we have to merge the expected counts to the traffic data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8a75b-bcf2-43dc-a963-42ebeb056f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = exp.rename(columns = {\"exp_car\": \"exp\"})\n",
    "traffic = traffic.merge(exp, on = [\"node_from\", \"node_to\"], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405c164-f7bc-4e20-b8a5-340e3e88a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "plt.style.use(\"bmh\")\n",
    "# Plots #\n",
    "    # Plot histogram\n",
    "traffic[\"exp\"].plot(kind = \"hist\", density = False, alpha = 0.8, bins = 70) # change density to true, because KDE uses density\n",
    "\n",
    "# X #\n",
    "ax.set_xlabel(\"Counts\")\n",
    "\n",
    "# Y #\n",
    "#ax.set_yticks([])\n",
    "    # Relabel the axis as \"Frequency\"\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Overall #\n",
    "ax.set_title(\"Expected traffic counts\")\n",
    "# Remove ticks and spines\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.rcParams['font.family'] = ['serif']\n",
    "#fig.savefig(\"figures/exp_hist.pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi=10, format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8d952-4d78-4dad-bb62-bf07a5629f42",
   "metadata": {},
   "source": [
    "To get the plot of the road network with expected traffic counts, we need to repeat the steps we did to get the plot for the observed counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e3bfb-d27f-41f6-9f1f-c0216b87cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[\"expcb\"] = exp.exp**(1/3)\n",
    "exp[\"expcb\"].hist(bins = 100)\n",
    "plt.title(\"Distribution of expected traffic count after $\\sqrt[3]{.}$-transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246347b-80c2-43f7-a0cd-20f55cfd8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot2 = cm.get_cmap('hot', int(exp.expcb.max()))\n",
    "newcolors2 = hot2(np.linspace(0, 1, int(exp.expcb.max())))\n",
    "darkgrey = np.array([0.5, 0.5, 0.5, 0.15]) #the fourth value sets the transparency of the color. This is necessary, because the grey roads would otherwise cover up the colored roads\n",
    "newcolors2[:1 :] = darkgrey\n",
    "\n",
    "newcmp2 = ListedColormap(newcolors2)\n",
    "\n",
    "plot_examples([hot2, newcmp2], lo = exp.expcb.min(), hi = exp.expcb.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e84ca-6736-4926-b80a-5556aa4dc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exp.exp, exp.expcb)\n",
    "plt.title(\"Transformed vs. untransformed exp (shows what each color represents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5caa2ca-843b-4295-8dd8-b3c66dea5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tick label positions\n",
    "for i in range(1,6): print((6 / exp[\"expcb\"].max()) * i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01206a37-0521-4b7f-9d6f-ffcef5a93982",
   "metadata": {},
   "source": [
    "#### Add exp and expcb to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99507ac-73ae-4161-9445-98e5c7bb7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges2 = add_features_to_edge(exp, edges2, features = [\"exp\", \"expcb\"], node_from = \"node_from\", node_to = \"node_to\", indexerror = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df3aad-f1cc-4c84-9c40-2bd73155d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ox.graph_from_gdfs(nodes, edges2)\n",
    "ec = ox.plot.get_edge_colors_by_attr(graph, attr=\"expcb\", cmap= newcmp2)\n",
    "fig, ax = ox.plot_graph(graph, node_color=\"w\", node_edgecolor=\"k\", node_size=0, edge_color=ec, edge_linewidth=2, show = False) #weights does not work for linewidth\n",
    "\n",
    "# add colorbar\n",
    "sm = mpl.cm.ScalarMappable(cmap = newcmp_cb)\n",
    "sm.set_array([])\n",
    "cb = fig.colorbar(cm.ScalarMappable(cmap = newcmp_cb), ax = ax, location = 'right', shrink = 0.8, ticks = [0.149, 0.298, 0.447,0.596,0.745,0.894])\n",
    "cb.ax.set_yticklabels([r'$1.3 \\times 10^2$', r'$1 \\times 10^3$', r'$3.4 \\times 10^3$', r'$8 \\times 10^3$',r'$1.56 \\times 10^4$', r'$2.7 \\times 10^4$'])\n",
    "cb.ax.set_ylabel('expected cars', rotation = 90)\n",
    "\n",
    "#fig.savefig(\"playgorund/exp_intensities.pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi=1000, format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535013d-0924-4399-86d4-9c72b868250d",
   "metadata": {},
   "source": [
    "Finally, I also looked at the distribution of the difference between observed and expected counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dfc51-b19e-4bb0-9c53-fc8c0e1a2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic[\"obsexpdiff\"] = traffic[\"exp\"] - traffic[\"obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efd70a-9779-4c79-b4bf-75e4cc883542",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "plt.style.use(\"bmh\")\n",
    "# Plots #\n",
    "    # Plot histogram\n",
    "traffic[\"obsexpdiff\"].plot(kind = \"hist\", density = False, alpha = 0.8, bins = 50) # change density to true, because KDE uses density\n",
    "\n",
    "# X #\n",
    "ax.set_xlabel(\"Difference\")\n",
    "\n",
    "# Y #\n",
    "#ax.set_yticks([])\n",
    "    # Relabel the axis as \"Frequency\"\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Overall #\n",
    "ax.set_title(\"Difference between observed and expected road segment count\")\n",
    "# Remove ticks and spines\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.rcParams['font.family'] = ['serif']\n",
    "#fig.savefig(\"figures/obs_exp_diff.pdf\", bbox_inches = \"tight\", pad_inches = 0, dpi=10, format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd4da7-d261-4817-9724-0a4d648aa193",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges2.to_csv(\"Data/output/edges_with_counts.csv\", index = False)\n",
    "traffic.to_csv(\"Data/output/traffic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccf782-6aa5-4ada-a4f3-6241c33be3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store objects in environment so that you can load them into the notebook inspect_model_c.ipynb\n",
    "%store Ngraph\n",
    "%store edges2\n",
    "%store nodes\n",
    "%store traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e05d3-02de-4215-a5ab-2618d5a4997b",
   "metadata": {},
   "source": [
    "# Cluster analysis\n",
    "I did this before I realised that exp should be an explanatory variable. This code is not up to date, however, I am leaving this in here as inspiration for the next person that might have more variables and wants to perform a clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad028b-3808-4b3f-9e21-f269abe19ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89ebf5-6bb8-4e95-af3f-62ee254dbb9d",
   "metadata": {},
   "source": [
    "### without ratio in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83fe15-5753-4ac6-9bc8-a45834e70a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldat = edges3[['cuberoot_ratio', 'popdens', \n",
    "       'is_bridge', 'maxmaxspeed', 'maxlanes']]\n",
    "modeldat = modeldat.dropna()\n",
    "crratio = modeldat[\"cuberoot_ratio\"]\n",
    "modeldat = modeldat.drop(columns = \"cuberoot_ratio\")\n",
    "scaler = StandardScaler()\n",
    "scaled_modeldat = scaler.fit_transform(modeldat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918bb28-638c-4608-ba7b-d53f995bf4c2",
   "metadata": {},
   "source": [
    "#### 2d/ 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64f4cb-99df-4da9-9bbb-cf15c9be7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "components = pca.fit_transform(scaled_modeldat)\n",
    "\n",
    "plt.scatter(components[:,0], components[:,1], c = crratio)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632062a-3db6-4f2f-84ce-be4d00d8a1fe",
   "metadata": {},
   "source": [
    "#### 3d/ 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff754c22-7e42-4a8e-bc15-3e83e66e8fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "components = pca.fit_transform(scaled_modeldat)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "p = ax.scatter3D(components[:,0], components[:,1], components[:,2], c = crratio)\n",
    "fig.colorbar(p, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ec5d1-633a-4cc2-8431-02ecd5af6f57",
   "metadata": {},
   "source": [
    "### With ratio in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66606cd4-19ad-4d85-ad7b-1eaed2b89e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldat = edges3[['cuberoot_ratio', 'popdens', \n",
    "       'is_bridge', 'maxmaxspeed', 'maxlanes']]\n",
    "modeldat = modeldat.dropna()\n",
    "crratio = modeldat[\"cuberoot_ratio\"]\n",
    "#modeldat = modeldat.drop(columns = \"cuberoot_ratio\")\n",
    "scaler = StandardScaler()\n",
    "scaled_modeldat = scaler.fit_transform(modeldat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac3aff-95b5-4afc-bddb-0e5207dc0409",
   "metadata": {},
   "source": [
    "#### 2d/ 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d51dc8-2e84-45bd-bb78-1cb0033a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "components = pca.fit_transform(scaled_modeldat)\n",
    "\n",
    "plt.scatter(components[:,0], components[:,1], c = crratio)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404da07d-6c89-4675-b483-f4fb2d7c63fb",
   "metadata": {},
   "source": [
    "#### 3d/ 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e672f-d941-4e97-bb83-5ce6c053680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "components = pca.fit_transform(scaled_modeldat)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "p = ax.scatter3D(components[:,0], components[:,1], components[:,2], c = crratio)\n",
    "fig.colorbar(p, ax = ax)\n",
    "#ax.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
